{"status":"success","code":200,"data":{"id":6,"title":"Vue前端总结——SEO优化","desc":"博客上线也有一段时间了，也在各大搜索引擎上提交了收录信息，但没啥用，闲着无聊就开始搞起seo了，vue 作为一个单页面应用，都是通过js来渲染页面，这就导致了蜘蛛在爬取网站的时候只能获取到一个空壳。没有信息自然也不会被收录。于是开始研究Vue seo优化问题.","content":"## 前言\n\n博客上线也有一段时间了，也在各大搜索引擎上提交了收录信息，但没啥用，闲着无聊就开始搞起seo了，vue 作为一个单页面应用，都是通过js来渲染页面，这就导致了蜘蛛在爬取网站的时候只能获取到一个空壳。没有信息自然也不会被收录。于是开始研究Vue seo优化问题，本来想使用官方的做法服务器渲染，但这样会导致很多问题，由于我的功能已经开发好了，如果使用服务器渲染，那我的整个项目都要进行重构，费时费力。而且我使用的阿里云学生服务器，性能也不够用啊！于是我采用了预渲染的方式，针对蜘蛛爬虫，在服务器开一个小灶给它，通过nginx服务器来判断是否为爬虫（通过请求头判断的），如果为爬虫就把请求转发的预渲染服务器中，然后再把渲染好的页面返回给爬虫，大概时这么个思想。由于方案太多前前后后试了几个方法。最后使用了`puppeteer`（性能好）\n\n### `puppeteer`渲染\n\n>  Puppeteer 是 Chrome 开发团队在 2017 年发布的一个 Node.js 包，用来模拟 Chrome 浏览器的运行 \n\n由于我`Linux`还是不熟练，所以使用的宝塔面板配置的，可以在宝塔面板中下一个pm2管理器（ *管理*你的node进程，也包括了node.js和npm ）安装成功后就可以按下面方法配置。[Puppeteer Api](https://zhaoqize.github.io/puppeteer-api-zh_CN/#?product=Puppeteer&version=v5.2.1&show=api-puppeteerconnectoptions)\n\n- 首先安装`puppeteer`：npm install puppeteer --save\n\n- 安装依赖： \n\n- ```text\n  # 依赖库\n  yum install pango.x86_64 libXcomposite.x86_64 libXcursor.x86_64 libXdamage.x86_64 libXext.x86_64 libXi.x86_64 libXtst.x86_64 cups-libs.x86_64 libXScrnSaver.x86_64 libXrandr.x86_64 GConf2.x86_64 alsa-lib.x86_64 atk.x86_64 gtk3.x86_64 -y\n  \n  # 字体\n  yum install ipa-gothic-fonts xorg-x11-fonts-100dpi xorg-x11-fonts-75dpi xorg-x11-utils xorg-x11-fonts-cyrillic xorg-x11-fonts-Type1 xorg-x11-fonts-misc -y\n  ```\n\n 接下来就是配置服务器代码了\npuppeter.js性能优化，去除不必要的功能，提高性能。\n\n```javascript\nconst puppeteer = require('puppeteer')\nconst MAX_WSE = 2; //启动几个浏览器 \nlet WSE_LIST = []; //存储browserWSEndpoint列表\n//负载均衡\n(async () => {\n\tfor (var i = 0; i < MAX_WSE; i++) {\n\t\tconst browser = await puppeteer.launch({\n            //无头模式\n\t\t\theadless: true,\n            //参数\n\t\t\targs: [\n\t\t\t\t'--disable-gpu',\n\t\t\t\t'--disable-dev-shm-usage',\n\t\t\t\t'--disable-setuid-sandbox',\n\t\t\t\t'--no-first-run',\n\t\t\t\t'--no-sandbox',\n\t\t\t\t'--no-zygote',\n\t\t\t\t'--single-process'\n\t\t\t]\n\t\t});\n\t\tbrowserWSEndpoint = await browser.wsEndpoint();\n\t\tWSE_LIST.push(browserWSEndpoint);\n\t}\n})();\n\nmodule.exports = WSE_LIST\n```\n\nspider.js渲染请求的页面\n\n```javascript\nconst puppeteer = require('puppeteer')\nconst WSE_LIST = require('./puppeteer-pool.js')\nconst spider = async (url) => {\n\t\n\tlet tmp = Math.floor(Math.random() * WSE_LIST.length);\n\t//随机获取浏览器\n\tlet browserWSEndpoint = WSE_LIST[tmp];\n\t//连接\n\tconst browser = await puppeteer.connect({\n\t\tbrowserWSEndpoint\n\t});\n\t//打开一个标签页\n\tvar page = await browser.newPage();\n\t//打开网页\n\tawait page.goto(url, {\n\t\ttimeout: 0, //连接超时时间，单位ms\n\t\twaitUntil: 'networkidle0' //网络空闲说明已加载完毕\n\t})\n\t//获取渲染好的页面源码。不建议使用await page.content();获取页面，因为在我测试中发现，页面还没有完全加载。就获取到了。页面源码不完整。也就是动态路由没有加载。vue路由也配置了history模式\n\tvar html = await page.evaluate(() => {\n\t\treturn document.getElementsByTagName('html')[0].outerHTML;\n\t});\n\n\tawait page.close();\n\n\treturn html;\n}\n\n\nmodule.exports = spider;\n```\n\nserver.js，通过express 开启一个服务器。接受转发的请求\n\n```javascript\nvar express = require('express');\nvar app = express();\nvar spider = require(\"./spider1.js\")\nvar minify = require('html-minifier').minify;\napp.get('*', async (req, res, next) => {\n\t// 部署到服务器的完整URL\n\t var url = req.protocol + '://'+ req.hostname + req.originalUrl;\n\tconsole.log('请求的完整URL：' + url);\n\tvar content = await spider(url).catch((error) => {\n\t\tconsole.log(error);\n\t\tres.send('获取html内容失败');\n\t\treturn;\n\t});\n    //由于是直接获取的源码，下面通过minify库压缩代码，也不知道是不是多余的。\n\tcontent=minify(content,{removeComments: true,collapseWhitespace: true,minifyJS:true, minifyCSS:true});\n\tres.send(content);\n});\n//监听3000端口\napp.listen(3000, () => {\n\tconsole.log('预渲染服务已启动！');\n});\n```\nNginx配置\n\n```shell\nupstream spider_server {\n  server localhost:3000;\n}\nserver\n{\n    location / {\n        # 蜘蛛爬虫处理\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header REMOTE-HOST $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        if ($http_user_agent ~* \"spider|bot\") {\n            proxy_pass http://spider_server;\n        }\n\n        try_files $uri $uri/ @router;\n    }\n    location @router {\n        rewrite ^(.*)$ /index.html last;\n    }\n    ……\n```\n###  `PhantomJS` \n\n刚开始接触的就是这种方法，后来了解`puppeteer`出来了，` PhantomJS `开发者就不维护了。也和`puppeteer`做了性能对比，性能也不行。这也不是最关键的，在我用百度站长工具爬取我的文章是，发现文章并没有渲染，可能是因为使用了新的语法了吧。毕竟开发者也不维护了。所以直接放代码就不过多的解释了。\n\n```javascript\n// spider.js\n\"use strict\";\n\n// 单个资源等待时间，避免资源加载后还需要加载其他资源\nvar resourceWait = 500;\nvar resourceWaitTimer;\n\n// 最大等待时间\nvar maxWait = 5000;\nvar maxWaitTimer;\n\n// 资源计数\nvar resourceCount = 0;\n\n// PhantomJS WebPage模块\nvar page = require('webpage').create();\n\n// NodeJS 系统模块\nvar system = require('system');\n\n// 从CLI中获取第二个参数为目标URL\nvar url = system.args[1];\n\n// 设置PhantomJS视窗大小\npage.viewportSize = {\n    width: 1280,\n    height: 1014\n};\n\n// 获取镜像\nvar capture = function(errCode){\n\n    // 外部通过stdout获取页面内容\n    console.log(page.content);\n\n    // 清除计时器\n    clearTimeout(maxWaitTimer);\n\n    // 任务完成，正常退出\n    phantom.exit(errCode);\n\n};\n\n// 资源请求并计数\npage.onResourceRequested = function(req){\n    resourceCount++;\n    clearTimeout(resourceWaitTimer);\n};\n\n// 资源加载完毕\npage.onResourceReceived = function (res) {\n\n    // chunk模式的HTTP回包，会多次触发resourceReceived事件，需要判断资源是否已经end\n    if (res.stage !== 'end'){\n        return;\n    }\n\n    resourceCount--;\n\n    if (resourceCount === 0){\n\n        // 当页面中全部资源都加载完毕后，截取当前渲染出来的html\n        // 由于onResourceReceived在资源加载完毕就立即被调用了，我们需要给一些时间让JS跑解析任务\n        // 这里默认预留500毫秒\n        resourceWaitTimer = setTimeout(capture, resourceWait);\n\n    }\n};\n\n// 资源加载超时\npage.onResourceTimeout = function(req){\n    resouceCount--;\n};\n\n// 资源加载失败\npage.onResourceError = function(err){\n    resourceCount--;\n};\n\n// 打开页面\npage.open(url, function (status) {\n\n    if (status !== 'success') {\n\n        phantom.exit(1);\n\n    } else {\n\n        // 当改页面的初始html返回成功后，开启定时器\n        // 当到达最大时间（默认5秒）的时候，截取那一时刻渲染出来的html\n        maxWaitTimer = setTimeout(function(){\n\n            capture(2);\n\n        }, maxWait);\n\n    }\n\n});\n```\n\nserver.js\n\n```javascript\n// server.js\n// ExpressJS调用方式\nvar express = require('express');\nvar app = express();\n// 引入NodeJS的子进程模块\nvar child_process = require('child_process');\n\napp.get('*', function(req, res){\n\n    // 完整URL\n    var url = req.protocol + '://'+ req.hostname + req.originalUrl;\n\n    // 预渲染后的页面字符串容器\n    var content = '';\n\n    // 开启一个phantomjs子进程\n    var phantom = child_process.spawn('phantomjs', ['spider.js', url]);\n\n    // 设置stdout字符编码\n    phantom.stdout.setEncoding('utf8');\n\n    // 监听phantomjs的stdout，并拼接起来\n    phantom.stdout.on('data', function(data){\n        content += data.toString();\n    });\n\n    // 监听子进程退出事件\n    phantom.on('exit', function(code){\n        switch (code){\n            case 1:\n                console.log('加载失败');\n                res.send('加载失败');\n                break;\n            case 2:\n                console.log('加载超时: '+ url);\n                res.send(content);\n                break;\n            default:\n                res.send(content);\n                break;\n        }\n    });\n\n});\n\napp.listen(3000, function () {\n  console.log('Spider app listening on port 3000!');\n});\n\n```\n\n### `Prerender`\n\n使用`Prerender`优化seo,经过我的测试，这种方法要优于`PhantomJS`但不如`puppeteer`(都在服务器上测试，且访问同样的页面)，而且还要使用`Chrome`\n\n#### 安装Chrome\n\n- 配置yum源\n  国内无法访问Google，需要配置yum源，在目录 /etc/yum.repos.d/ 下新建google-chrome.repo文件\n\n  ```\n  cd /ect/yum.repos.d/\n  touch google-chrome.repo\n  ```\n\n- 通过vi编辑器添加内容\n\n  ```\n  vi google-chrome.repo\n  [google-chrome]\n  name=google-chrome\n  baseurl=http://dl.google.com/linux/chrome/rpm/stable/$basearch\n  enabled=1\n  gpgcheck=1\n  gpgkey=https://dl-ssl.google.com/linux/linux_signing_key.pub\n  ```\n\n- 安装运行\n\n  ```\n  // 国内推荐\n  yum -y install google-chrome-stable --nogpgcheck\n  ```\n\n- 安装成功后路径\n  `/opt/google/chrome`\n\n- 安装成功后无法打开chrome\n\n  主要的解决办法是找到`/opt/google/chrome`目录，编辑`google-chrome`文件，把最后一行的 \n\n  ```\n  exec -a \"$0\" \"$HERE/chrome\" \"$@\"\n  ```\n\n  修改为\n\n  ```\n  exec -a \"$0\" \"$HERE/chrome\" \"$@\" --user-data-dir $HOME\n  ```\n\n\n#### 安装Prerender\n\n>  Prerender 是一个采用[phantomjs](http://phantomjs.org/)的服务，它是可以对 JavaScript 页面进行静态化  [下载地址](https://github.com/prerender/prerender.git)\n\n```\ngit clone https://github.com/prerender/prerender.git\ncd prerender\nnpm install\n#启动server.js， 默认监听3000端口\nnode server.js\n```\n\n通过curl 命令解析你要访问的网址，如果返回渲染好的html 就说明成功了。\n\n```\ncurl http://localhost:3000/你的网站路径\n```\n\n#### Nginx配置\n\n```\nlocation / {\n\t# 表示是否需要代理\n\tset $prerender 0;\n\t# 代理地址\n\tset $prerender_url \"http://127.0.0.1:3000\";\n\n\t# 判断请求是否来自蜘蛛，如果是则表示需要代理\n\tif ($http_user_agent ~* \"baiduspider|Googlebot|360Spider|Bingbot|Sogou Spider|Yahoo! Slurp China|Yahoo! Slurp|twitterbot|facebookexternalhit|rogerbot|embedly|quora link preview|showyoubot|outbrain|pinterest|slackbot|vkShare|W3C_Validator\") {\n \t\tset $prerender 1;\n \t}\n \n\tif ($prerender = 1) {\n\t\tproxy_pass $prerender_url;\n\t\trewrite ^(.*)$ /https://$host$1 break;\n\t}\n}\n```\n\n## 总结\n\n这三种方法我都在我的网站服务器测试过，并通过百度官方的抓取诊断测试过，也使用过`Postman`工具本地批量抓取测试。虽然说`PhantomJS`响应时间都短，但它不适合我的项目，因为部分页面没有渲染出来（文章），而`Prerender`在爬取的时候服务器几乎满载了。而且部分页面也没渲染完全。经过我不断地百度最后才使用了`puppeteer`简单不复杂，配置语句也基本能看懂。\n### 效果\n虽然更新不频繁，但是经过几个月的检验，这种方法可行，现在博客页面也被百度收录了！\n![百度收录](https://p.pstatp.com/origin/137ba00031ef636e84003)\n![谷歌收录](https://p.pstatp.com/origin/ff7000014cd7842bb658)\n\n> 本文配置，没有经严格的测试，若有不足，敬请指出","img":"https://p.pstatp.com/origin/13866000017d0d695d411","classty":"前端","channels":null,"name":"Baymax","click":4,"like":1,"is_show":1,"head_show":1,"share_show":1,"copyright_show":1,"message_show":0,"deleted_at":1,"created_at":"2020-09-04T12:32:25.000000Z","updated_at":"2021-01-23T03:17:45.000000Z","label":["Seo","Puppeteer","PhantomJS","Prerender"],"view_count":1,"prevArticle":[{"id":5,"title":"Vue博客前端总结——Vue全家桶"}],"nextrAticle":[{"id":7,"title":"使用vue制作一个属于自己的音乐播放器"}]}}